{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model parameter tuning and evalution using Gridsearch\n",
    "USA World Series Results,\n",
    "Run on \"Diff\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opp</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Poss_Time_Diff</th>\n",
       "      <th>Score_Diff</th>\n",
       "      <th>Conv_Diff</th>\n",
       "      <th>Tries_Diff</th>\n",
       "      <th>Passes_Diff</th>\n",
       "      <th>Contestable_KO_Win_pct_Diff</th>\n",
       "      <th>PenFK_Against_Diff</th>\n",
       "      <th>RuckMaul_Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>-99 : -75</th>\n",
       "      <th>-74 : -25</th>\n",
       "      <th>-24 : -1</th>\n",
       "      <th>0 : 25</th>\n",
       "      <th>26 : 50</th>\n",
       "      <th>51 : 75</th>\n",
       "      <th>76 : 100</th>\n",
       "      <th>101 : 125</th>\n",
       "      <th>126 : 150</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>13.966480</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>25.925926</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALES</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>7.471264</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>27.868852</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KENYA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>-33.136095</td>\n",
       "      <td>-44.444444</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>51.758794</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.119403</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIJI</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>12.880562</td>\n",
       "      <td>-20.833333</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Opp      Tournament  Poss_Time_Diff  Score_Diff  Conv_Diff  \\\n",
       "0    AUSTRALIA  2015_Cape_Town       13.966480  -10.638298 -14.285714   \n",
       "1        WALES  2015_Cape_Town        7.471264   15.555556  14.285714   \n",
       "2        KENYA  2015_Cape_Town      -33.136095  -44.444444 -33.333333   \n",
       "3  NEW ZEALAND  2015_Cape_Town       51.758794   33.333333  33.333333   \n",
       "4         FIJI  2015_Cape_Town       12.880562  -20.833333 -25.000000   \n",
       "\n",
       "   Tries_Diff  Passes_Diff  Contestable_KO_Win_pct_Diff  PenFK_Against_Diff  \\\n",
       "0    0.250000    25.925926                   -50.000000            0.000000   \n",
       "1    0.083333    27.868852                    25.000000          -20.000000   \n",
       "2   -0.750000   -10.638298                   -16.666667           66.666667   \n",
       "3    0.000000    76.119403                   -75.000000          -50.000000   \n",
       "4    0.266667    38.461538                   -66.666667          -33.333333   \n",
       "\n",
       "   RuckMaul_Diff   ...    -99 : -75  -74 : -25  -24 : -1  0 : 25  26 : 50  \\\n",
       "0       0.000000   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "1    -100.000000   ...          0.0        0.0       0.0    12.5      0.0   \n",
       "2      60.000000   ...          0.0        0.0      -5.0     0.0      0.0   \n",
       "3    -100.000000   ...        -37.5        0.0       0.0     0.0      0.0   \n",
       "4     -33.333333   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "\n",
       "   51 : 75  76 : 100  101 : 125  126 : 150  Result  \n",
       "0      0.0       0.0        0.0        0.0       0  \n",
       "1      0.0       0.0        0.0        0.0       1  \n",
       "2      0.0       0.0        0.0        0.0       0  \n",
       "3      0.0       0.0        0.0        0.0       1  \n",
       "4      0.0       0.0        0.0        0.0       0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data - USA's differential data\n",
    "df = pd.read_csv('../data/output/new_features_diffdata.csv')\n",
    "#Import validation data\n",
    "valdf = pd.read_csv('../data/output/new_features_diffdata_validate.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 27 columns):\n",
      "Opp                            156 non-null object\n",
      "Tournament                     156 non-null object\n",
      "Poss_Time_Diff                 156 non-null float64\n",
      "Score_Diff                     156 non-null float64\n",
      "Conv_Diff                      156 non-null float64\n",
      "Tries_Diff                     156 non-null float64\n",
      "Passes_Diff                    156 non-null float64\n",
      "Contestable_KO_Win_pct_Diff    156 non-null float64\n",
      "PenFK_Against_Diff             156 non-null float64\n",
      "RuckMaul_Diff                  156 non-null float64\n",
      "Ruck_Win_pct_Diff              156 non-null float64\n",
      "Cards_diff                     156 non-null float64\n",
      "Lineout_Win_Pct_Diff           156 non-null float64\n",
      "Scrum_Win_Pct_Diff             156 non-null float64\n",
      "-175 : -150                    156 non-null float64\n",
      "-149 : -125                    156 non-null float64\n",
      "-124 : -100                    156 non-null float64\n",
      "-99 : -75                      156 non-null float64\n",
      "-74 : -25                      156 non-null float64\n",
      "-24 : -1                       156 non-null float64\n",
      "0 : 25                         156 non-null float64\n",
      "26 : 50                        156 non-null float64\n",
      "51 : 75                        156 non-null float64\n",
      "76 : 100                       156 non-null float64\n",
      "101 : 125                      156 non-null float64\n",
      "126 : 150                      156 non-null float64\n",
      "Result                         156 non-null int64\n",
      "dtypes: float64(24), int64(1), object(2)\n",
      "memory usage: 33.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Opp',\n",
       " 'Tournament',\n",
       " 'Poss_Time_Diff',\n",
       " 'Score_Diff',\n",
       " 'Conv_Diff',\n",
       " 'Tries_Diff',\n",
       " 'Passes_Diff',\n",
       " 'Contestable_KO_Win_pct_Diff',\n",
       " 'PenFK_Against_Diff',\n",
       " 'RuckMaul_Diff',\n",
       " 'Ruck_Win_pct_Diff',\n",
       " 'Cards_diff',\n",
       " 'Lineout_Win_Pct_Diff',\n",
       " 'Scrum_Win_Pct_Diff',\n",
       " '-175 : -150',\n",
       " '-149 : -125',\n",
       " '-124 : -100',\n",
       " '-99 : -75',\n",
       " '-74 : -25',\n",
       " '-24 : -1',\n",
       " '0 : 25',\n",
       " '26 : 50',\n",
       " '51 : 75',\n",
       " '76 : 100',\n",
       " '101 : 125',\n",
       " '126 : 150',\n",
       " 'Result']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of features to drop that are unneccessary or will bias the prediction\n",
    "droplist = ['Opp', 'Score_Diff', 'Tries_Diff','Tournament', 'Conv_Diff','-175 : -150', '-149 : -125','-124 : -100', '-99 : -75', '-74 : -25','-24 : -1','0 : 25','26 : 50','51 : 75','76 : 100','101 : 125','126 : 150']\n",
    "\n",
    "rf_data = df.drop((droplist), axis=1)\n",
    "#Drop rows with Result == \"T\" (Ties). This label messes up classification models\n",
    "rf_data.drop(rf_data[rf_data.Result == 2].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151.000000\n",
       "mean       0.562914\n",
       "std        0.497677\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Result, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data.head()\n",
    "#Check to insure 'Result' only contains 2 values (W, L)\n",
    "rf_data['Result'].describe()\n",
    "#rf_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull out the variable we're trying to predict: 'Result'\n",
    "X = rf_data.drop('Result',axis=1)\n",
    "y = rf_data['Result']\n",
    "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train/test/validate sets\n",
    "#OR, keep as is and use new data for validate\n",
    "#156 rows in original dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set\n",
    "Imported last two series stops (London & Paris - 12 matches total) to use as a validation set.\n",
    "\n",
    "Need to incorporate into larger data set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of features to drop that are unneccessary or will bias the prediction\n",
    "droplist = ['Opp', 'Score_Diff', 'Tries_Diff','Tournament', 'Conv_Diff','-175 : -150', '-149 : -125','-124 : -100', '-99 : -75', '-74 : -25','-24 : -1','0 : 25','26 : 50','51 : 75','76 : 100','101 : 125','126 : 150']\n",
    "\n",
    "rf_val_data = valdf.drop((droplist), axis=1)\n",
    "\n",
    "#Drop rows with Result == \"T\" (Ties). This label messes up classification models\n",
    "rf_val_data.drop(rf_val_data[rf_val_data.Result == 2].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull out the variable we're trying to predict: 'Result'\n",
    "X_val = rf_val_data.drop('Result',axis=1)\n",
    "y_val = rf_val_data['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_val = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an XGBoost Classifier Model\n",
    "Info from https://jessesw.com/XG-Boost/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hyperparameter tuning/Grid Search¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for first grid search. Start tuning on the maximum depth of the trees first, \n",
    "#along with the min_child_weight, which is very similar to min_samples_split in sklearn’s version \n",
    "#of gradient boosted trees. We set the objective to ‘binary:logistic’ since this is a binary \n",
    "#classification problem\n",
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':101, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'random_state':101}\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) \n",
    "# Optimize for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=101, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=101, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 5, 7], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=101, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=101, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 5, 7], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the grid search\n",
    "optimized_GBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0169301 , 0.0161499 , 0.01471996, 0.01963601, 0.0180223 ,\n",
       "        0.01899333, 0.02069335, 0.01354899, 0.01116328]),\n",
       " 'std_fit_time': array([0.00071912, 0.00209905, 0.0020378 , 0.0009389 , 0.00391475,\n",
       "        0.00324873, 0.00205747, 0.00141454, 0.0011915 ]),\n",
       " 'mean_score_time': array([0.00177789, 0.00090137, 0.00093274, 0.00091143, 0.00147295,\n",
       "        0.00148501, 0.00089359, 0.00087299, 0.00078082]),\n",
       " 'std_score_time': array([4.86399729e-04, 4.58110241e-05, 1.01304433e-04, 2.67842450e-05,\n",
       "        1.01499061e-03, 6.88196484e-04, 1.06996563e-05, 2.44931137e-04,\n",
       "        6.70320100e-05]),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
       "  {'max_depth': 3, 'min_child_weight': 3},\n",
       "  {'max_depth': 3, 'min_child_weight': 5},\n",
       "  {'max_depth': 5, 'min_child_weight': 1},\n",
       "  {'max_depth': 5, 'min_child_weight': 3},\n",
       "  {'max_depth': 5, 'min_child_weight': 5},\n",
       "  {'max_depth': 7, 'min_child_weight': 1},\n",
       "  {'max_depth': 7, 'min_child_weight': 3},\n",
       "  {'max_depth': 7, 'min_child_weight': 5}],\n",
       " 'split0_test_score': array([0.68181818, 0.63636364, 0.54545455, 0.63636364, 0.63636364,\n",
       "        0.54545455, 0.63636364, 0.63636364, 0.54545455]),\n",
       " 'split1_test_score': array([0.59090909, 0.54545455, 0.63636364, 0.59090909, 0.54545455,\n",
       "        0.63636364, 0.54545455, 0.54545455, 0.63636364]),\n",
       " 'split2_test_score': array([0.66666667, 0.61904762, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.57142857, 0.61904762, 0.66666667, 0.57142857]),\n",
       " 'split3_test_score': array([0.55, 0.55, 0.6 , 0.55, 0.5 , 0.6 , 0.55, 0.5 , 0.6 ]),\n",
       " 'split4_test_score': array([0.55, 0.7 , 0.55, 0.55, 0.7 , 0.55, 0.55, 0.7 , 0.55]),\n",
       " 'mean_test_score': array([0.60952381, 0.60952381, 0.58095238, 0.59047619, 0.60952381,\n",
       "        0.58095238, 0.58095238, 0.60952381, 0.58095238]),\n",
       " 'std_test_score': array([0.05630702, 0.05712482, 0.03430855, 0.03505157, 0.07421686,\n",
       "        0.03430855, 0.03952929, 0.07421686, 0.03430855]),\n",
       " 'rank_test_score': array([1, 1, 6, 5, 1, 6, 6, 1, 6], dtype=int32),\n",
       " 'split0_train_score': array([1.        , 0.90361446, 0.77108434, 1.        , 0.89156627,\n",
       "        0.77108434, 1.        , 0.89156627, 0.77108434]),\n",
       " 'split1_train_score': array([1.        , 0.89156627, 0.74698795, 1.        , 0.89156627,\n",
       "        0.74698795, 1.        , 0.89156627, 0.74698795]),\n",
       " 'split2_train_score': array([1.        , 0.89285714, 0.78571429, 1.        , 0.88095238,\n",
       "        0.78571429, 1.        , 0.88095238, 0.78571429]),\n",
       " 'split3_train_score': array([0.98823529, 0.91764706, 0.8       , 0.98823529, 0.89411765,\n",
       "        0.8       , 0.98823529, 0.89411765, 0.8       ]),\n",
       " 'split4_train_score': array([0.98823529, 0.94117647, 0.8       , 0.98823529, 0.94117647,\n",
       "        0.8       , 0.98823529, 0.94117647, 0.8       ]),\n",
       " 'mean_train_score': array([0.99529412, 0.90937228, 0.78075731, 0.99529412, 0.89987581,\n",
       "        0.78075731, 0.99529412, 0.89987581, 0.78075731]),\n",
       " 'std_train_score': array([0.00576351, 0.018455  , 0.01999535, 0.00576351, 0.02114282,\n",
       "        0.01999535, 0.00576351, 0.02114282, 0.01999535])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check grid scores (see deprecation warning - change from grid_scores_ to cv_results_ attribute\n",
    "optimized_GBM.cv_results_\n",
    "# score decreased from RF to 62% from 71%:\n",
    "# mean: 0.62857, std: 0.13399, params: {'max_depth': 3, 'min_child_weight': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best parameters\n",
    "\n",
    "use these parameters (resulting in mean: 0.60952):\n",
    "\n",
    "mean: 0.60952, std: 0.11613, params: {'max_depth': 3, 'min_child_weight': 1}\n",
    "\n",
    "** params: {'max_depth': 3, 'min_child_weight': 1} **\n",
    "\n",
    "Adjust subsampling along with lowering the learning rate to see if that helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6095238095238096\n",
      "Best parameter set: {'max_depth': 3, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Best score and parameter set\n",
    "print(\"Best score: %s\" % (optimized_GBM.best_score_))\n",
    "print(\"Best parameter set: %s\" % (optimized_GBM.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=101, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=101, silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.1, 0.01], 'subsample': [0.7, 0.8, 0.9], 'n_estimators': [100, 500, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9], 'n_estimators': [100, 500, 1000]}\n",
    "ind_params = {'seed':101, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 1, 'random_state': 101}\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "# Run the grid search again\n",
    "optimized_GBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6190476190476191\n",
      "Best parameter set: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# check the Grid Scores again - increased to 0.67619 by tweaking parameters\n",
    "# Increased CV folds to cv=11, {'max_depth': 5, 'min_child_weight': 1}\n",
    "# mean: 0.68571, std: 0.13895, params: {'learning_rate': 0.1, 'subsample': 0.8}\n",
    "# Best score and parameter set\n",
    "print(\"Best score: %s\" % (optimized_GBM.best_score_))\n",
    "print(\"Best parameter set: %s\" % (optimized_GBM.best_params_))\n",
    "#optimized_GBM.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=101, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=101, silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.1, 0.01], 'subsample': [0.7, 0.8, 0.9], 'n_estimators': [100, 500, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final parameters:\n",
    "No increase in mean.\n",
    "\n",
    "Improved to 62% (mean: mean: 0.62857, std: 0.09520):\n",
    "\n",
    "**params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.9}**\n",
    "\n",
    "<code>\n",
    "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
    "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
    "       random_state=101, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=101, silent=True, subsample=1),\n",
    "       fit_params=None, iid='warn', n_jobs=-1,\n",
    "       params={'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.9},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='accuracy', verbose=0)\n",
    "</code>\n",
    "ind_params = {'seed':101, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 3, 'random_state': 101}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DMatrix\n",
    "To increase the performance of XGBoost's speed through many iterations of the training set, and since we are using only XGBoost's API and not sklearn's anymore, we can create a DMatrix. This sorts the data initially to optimize for XGBoost when it builds trees, making the algorithm more efficient. This is especially helpful when you have a very large number of training examples. To create a DMatrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our DMatrix to make XGBoost more efficient\n",
    "xgdmat = xgb.DMatrix(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Early Stopping CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'n_estimators': 100, 'learning_rate': 0.01, 'subsample': 0.9, 'max_depth': 3, 'min_child_weight': 1, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.352381</td>\n",
       "      <td>0.038095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.159524</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>0.361904</td>\n",
       "      <td>0.038095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.352381</td>\n",
       "      <td>0.038095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.024514</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.035635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.035635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "25          0.152381         0.023084         0.352381        0.038095\n",
       "26          0.159524         0.017817         0.361904        0.038095\n",
       "27          0.157143         0.020482         0.352381        0.038095\n",
       "28          0.150000         0.024514         0.342857        0.035635\n",
       "29          0.152381         0.020482         0.342857        0.035635"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "Test error mean of 0.361904, or 64% accuracy\n",
    "\n",
    "Now that we have our best settings, create this as an XGBoost object model that we can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our_params = {'eta': 0.1, 'seed':101, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':3} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "#sns.set(font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f20d710>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(final_gb, importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f5': 6, 'f6': 2, 'f3': 8, 'f0': 5, 'f7': 7, 'f2': 5, 'f1': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = final_gb.get_fscore()\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdmat = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = final_gb.predict(testdmat) # Predict using our testdmat\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred > 0.5] = 1\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test), 1-accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy is 54%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 8 15]\n",
      " [ 8 15]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.35      0.41        23\n",
      "           1       0.50      0.65      0.57        23\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        46\n",
      "   macro avg       0.50      0.50      0.49        46\n",
      "weighted avg       0.50      0.50      0.49        46\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "#Output confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "#import libraries to ignore UndefinedMetricWarning\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "#get the model's accuracy score\n",
    "accuracy_score(y_test, y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#print accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdmat = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = final_gb.predict(valdmat) # Predict using our testdmat\n",
    "#y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred[y_val_pred > 0.5] = 1\n",
    "y_val_pred[y_val_pred <= 0.5] = 0\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val_pred, y_val), 1-accuracy_score(y_val_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on validation data is 60%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1 3]\n",
      " [1 5]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        10\n",
      "   macro avg       0.56      0.54      0.52        10\n",
      "weighted avg       0.57      0.60      0.56        10\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "#Output confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_val,y_val_pred))\n",
    "\n",
    "#import libraries to ignore UndefinedMetricWarning\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "#get the model's accuracy score\n",
    "accuracy_score(y_val, y_val_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#print accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_val_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_val_pred, y_val, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
